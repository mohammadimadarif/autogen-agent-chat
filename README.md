# autogen-agent-chat
Overview

This project implements an AI agent chat system using AutoGen and Ollama. The system enables multi-agent conversations and uses a local LLM model (tinyllama) to process and respond to queries.

🚀 Features

Uses AutoGen for conversational AI agents.

Runs a local LLM model (tinyllama) via Ollama.

Supports multi-agent interactions.

Includes a user proxy agent to interact with the assistant.

Allows for code execution and tool integration.

🛠️ Prerequisites

1️⃣ Install Python and Virtual Environment

Ensure you have Python 3.8+ installed. Then, create and activate a virtual environment:

2️⃣ Install Required Dependencies

3️⃣ Install & Run Ollama

Download and install Ollama from Ollama's official website. After installation, start the Ollama service:

🏗️ Project Setup

Clone this repository:

Install dependencies:

Run the AI agent chat system:

🔬 Testing

You can start with a simple query:

🔧 Troubleshooting

If you get an Ollama model not found error, run:

If the server isn’t running, start it manually:

📝 License

This project is licensed under the MIT License. Feel free to modify and use it as needed.

🤝 Contributing

Pull requests are welcome! If you have suggestions or improvements, please open an issue.
